
# ğŸŒ¸ **MLOps Iris Classifier â€” End-to-End CI/CD Deployment (GitHub Actions Edition)**

This repository demonstrates a **complete MLOps workflow** using the classic **Iris dataset**, progressing from data preprocessing and model training to full web deployment through an automated **CI/CD (Continuous Integration and Continuous Deployment)** pipeline built with **GitHub Actions** and deployed to **Google Cloud Platform (GCP)**.

<p align="center">
  <img src="img/flask/flask_app.gif" alt="Deployed Flask Iris Classifier Application" style="width:100%; height:auto;" />
</p>

While the machine learning use case â€” **Iris species classification** â€” is intentionally simple, the projectâ€™s main objective is to showcase a **production-grade MLOps workflow** using **GitHub Actions** for automation, containerisation, and cloud deployment via **Google Kubernetes Engine (GKE)**.

## ğŸ§© **Project Overview**

This project walks through the **entire lifecycle** of a machine learning system â€” from raw data to live deployment â€” using a modular, reproducible, and scalable architecture.
Each stage builds on the previous one, ensuring consistent execution and traceability throughout the pipeline.

### ğŸŒ± **Stage 00 â€” Project Setup**

A structured repository layout was established, introducing:

* Core directories: `src/`, `pipeline/`, `artifacts/`, and `img/`
* Dependency management with **`uv`** for reproducible environments
* Editable package installation via `setup.py`
* Logging and exception-handling frameworks for traceable experimentation

This created the foundation for the remaining stages.

### ğŸ’¾ **Stage 01 â€” Data Processing**

The **`data_processing.py`** module handled the complete preprocessing workflow:

* Loading and cleaning the Iris dataset
* Handling outliers and missing values
* Splitting data into training and test sets
* Persisting processed artefacts (`X_train.pkl`, `y_test.pkl`, etc.)

All transformations were reproducible and logged to ensure consistent results.

### ğŸ§  **Stage 02 â€” Model Training**

The **`model_training.py`** module trained a **Decision Tree Classifier** and performed model evaluation, generating key metrics:

* Accuracy, precision, recall, and F1-score
* A confusion matrix (`confusion_matrix.png`)
* A serialised model file (`model.pkl`)

Exception handling and centralised logging ensured reliability during training.

### ğŸŒ¸ **Stage 03 â€” Flask Application**

A **Flask web interface** was built to deploy the trained model as an interactive web app.
Users can input sepal and petal dimensions and receive predictions in real time.

This stage introduced:

* A responsive HTML front-end (`templates/index.html`)
* CSS styling (`static/style.css`)
* Flask integration via `app.py` for live inference

<p align="center">
  <img src="img/flask/flask_app.png" alt="Flask Iris Classifier Application" style="width:100%; height:auto;" />
</p>

### âš™ï¸ **Stage 04 â€” Training Pipeline**

The **`pipeline/training_pipeline.py`** script unified **data processing** and **model training** into a single orchestrated pipeline, automating every key step.

It provides a reproducible execution workflow that can be triggered locally or by external automation tools (e.g. CI/CD).
This was the bridge between local experimentation and cloud automation.

### â˜ï¸ **Stage 05 â€” Google Cloud Platform (GCP) Setup**

The cloud infrastructure was configured within **Google Cloud Platform** to support containerised ML workloads.

Key setup tasks included:

* Enabling APIs for **Kubernetes Engine**, **Artifact Registry**, and **Compute Engine**
* Creating an **Artifact Registry** repository (`mlops-iris-iii`) in `us-central1`
* Generating a **Service Account** with roles for Artifact Registry and Kubernetes deployment
* Creating a **GKE Autopilot cluster** (`autopilot-cluster-1`) for managed workloads

This established the secure, scalable backbone for automated deployment.

### ğŸš€ **Stage 06 â€” CI/CD Deployment (GitHub Actions â†’ GCP)**

Finally, the project integrated **GitHub Actions** to automate the build-and-deploy workflow.
Each push to the `main` branch triggers the pipeline defined in **`.github/workflows/deploy.yml`**.

The CI/CD sequence:

1. **Build** â€” Create a Docker image for the Flask app using the `Dockerfile`
2. **Push** â€” Upload the image to **Google Artifact Registry**
3. **Deploy** â€” Apply `kubernetes-deployment.yaml` to **GKE** to update the live application

The pipeline uses the official **`google-github-actions`** modules for authentication, image management, and Kubernetes deployment.

<p align="center">
  <img src="img/github_actions/workflow_success.png" alt="GitHub Actions Workflow Success" style="width:100%; height:auto;" />
</p>

Once completed, the application becomes publicly available through the external **LoadBalancer endpoint** exposed by GKE.

## ğŸ’¡ **Why GitHub Actions?**

GitHub Actions was chosen for its **tight integration**, **ease of setup**, and **robust cloud support**.

### âœ… **Key Advantages**

* **Native integration** â€” workflows trigger automatically on push or pull requests
* **Simple YAML configuration** stored under `.github/workflows/`
* **Secure secret management** through repository settings
* **First-class GCP support** with official authentication actions
* **Zero-infrastructure overhead** â€” runs on GitHub-hosted runners
* **Fast, scalable execution** â€” ideal for iterative machine learning workflows

These features make **GitHub Actions** a clean, lightweight, and powerful choice for modern CI/CD in MLOps.

## ğŸ—‚ï¸ **Final Project Structure**

```text
mlops_iris_classifier/
â”œâ”€â”€ .venv/                          # ğŸ§© Local virtual environment (created by uv)
â”œâ”€â”€ artifacts/                      # ğŸ’¾ Raw, processed, and model artefacts
â”‚   â”œâ”€â”€ raw/
â”‚   â”œâ”€â”€ processed/
â”‚   â””â”€â”€ models/
â”œâ”€â”€ pipeline/
â”‚   â””â”€â”€ training_pipeline.py         # Unified data processing + model training
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_processing.py
â”‚   â”œâ”€â”€ model_training.py
â”‚   â”œâ”€â”€ logger.py
â”‚   â””â”€â”€ custom_exception.py
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html                  # Flask UI
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ style.css
â”‚   â””â”€â”€ img/app_background.jpg
â”œâ”€â”€ img/
â”‚   â”œâ”€â”€ flask/flask_app.gif         # Animated Flask app demo
â”‚   â”œâ”€â”€ github_actions/             # Screenshots for GitHub + GCP setup
â”‚   â””â”€â”€ gcp/
â”œâ”€â”€ Dockerfile                      # ğŸ³ Container image definition
â”œâ”€â”€ kubernetes-deployment.yaml      # â˜¸ï¸ Kubernetes deployment specification
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ deploy.yml              # âš™ï¸ GitHub Actions CI/CD pipeline
â”œâ”€â”€ app.py                          # Flask application entry point
â”œâ”€â”€ pyproject.toml                  # Project metadata and dependencies
â”œâ”€â”€ setup.py                        # Editable install support
â””â”€â”€ requirements.txt                # Python dependencies
```

## ğŸŒ **End-to-End Workflow Summary**

1. **Data Processing** â†’ clean, split, and persist artefacts
2. **Model Training** â†’ train and evaluate the Decision Tree Classifier
3. **Flask Application** â†’ serve predictions via web interface
4. **Pipeline Orchestration** â†’ unify preprocessing + training
5. **GCP Setup** â†’ configure cluster, registry, and permissions
6. **CI/CD Deployment** â†’ automate build â†’ push â†’ deploy to GKE

## âœ… **In Summary**

This project transforms a simple Iris classification task into a **fully automated MLOps pipeline** using **GitHub Actions** and **Google Cloud Platform**.
It demonstrates how to take a traditional ML workflow â€” data, model, and app â€” and operationalise it through a reproducible, cloud-native CI/CD system that delivers scalable, production-ready deployments with every code push.