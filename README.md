# ğŸ§© **Training Pipeline â€” MLOps Weather Prediction**

This branch extends the **MLOps Weather Prediction** project by introducing the **`training_pipeline.py`** file inside the `pipeline/` directory.
It marks the **third executable stage** of the project, where all previous workflow components â€” **data preprocessing** and **model training** â€” are orchestrated together into a single, reproducible **end-to-end pipeline**.

## ğŸ§  **Overview**

The `training_pipeline.py` script serves as the **workflow controller** of the Weather Prediction MLOps system.
It sequentially runs the preprocessing and model training modules defined in `src/`, transforming raw meteorological data into a fully trained and evaluated model â€” ready for deployment or continuous integration workflows.

### ğŸ” Core Responsibilities

| Stage | Operation                  | Description                                                                                   |
| ----: | -------------------------- | --------------------------------------------------------------------------------------------- |
|   1ï¸âƒ£ | **Run Data Processing**    | Executes the `DataProcessing` class to clean, encode, and split raw weather data.             |
|   2ï¸âƒ£ | **Train & Evaluate Model** | Executes the `ModelTraining` class to train an XGBoost model and compute performance metrics. |

## ğŸ—‚ï¸ **Updated Project Structure**

```text
mlops_weather_prediction/
â”œâ”€â”€ .venv/                           # ğŸ§© Local virtual environment (created by uv)
â”œâ”€â”€ artifacts/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ weather_data.csv         # ğŸŒ¦ï¸ Input weather dataset
â”‚   â”œâ”€â”€ processed/                   # ğŸ’¾ Data prepared by preprocessing
â”‚   â”‚   â”œâ”€â”€ X_train.pkl
â”‚   â”‚   â”œâ”€â”€ X_test.pkl
â”‚   â”‚   â”œâ”€â”€ y_train.pkl
â”‚   â”‚   â””â”€â”€ y_test.pkl
â”‚   â””â”€â”€ models/                      # ğŸ§  Trained model artefacts
â”‚       â””â”€â”€ model.pkl
â”œâ”€â”€ pipeline/                        # ğŸ”„ End-to-end workflow orchestration
â”‚   â””â”€â”€ training_pipeline.py         # Executes full pipeline (data + training)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ custom_exception.py          # Unified and detailed exception handling
â”‚   â”œâ”€â”€ logger.py                    # Centralised logging configuration
â”‚   â”œâ”€â”€ data_processing.py           # ğŸŒ¦ï¸ Data preparation and encoding
â”‚   â””â”€â”€ model_training.py            # âš™ï¸ Model training, evaluation, and persistence
â”œâ”€â”€ static/                          # ğŸŒ Visual assets (optional)
â”œâ”€â”€ templates/                       # ğŸ§© Placeholder for web/API templates
â”œâ”€â”€ .gitignore                       # ğŸš« Git ignore rules
â”œâ”€â”€ .python-version                  # ğŸ Python version pin
â”œâ”€â”€ pyproject.toml                   # âš™ï¸ Project metadata and uv configuration
â”œâ”€â”€ requirements.txt                 # ğŸ“¦ Python dependencies
â”œâ”€â”€ setup.py                         # ğŸ”§ Editable install support
â””â”€â”€ uv.lock                          # ğŸ”’ Locked dependency versions
```

## âš™ï¸ **How to Run the Training Pipeline**

After ensuring that the raw dataset is present at `artifacts/raw/data.csv`, you can execute the **entire pipeline** â€” from preprocessing to model training â€” using:

```bash
python pipeline/training_pipeline.py
```

### âœ… **Expected Successful Output**

```console
2025-11-08 13:12:45,931 - INFO - Data loaded successfully. Shape: (145460, 23)
2025-11-08 13:12:46,017 - INFO - Basic data preprocessing completed.
2025-11-08 13:12:46,043 - INFO - Label encoding completed.
2025-11-08 13:12:46,088 - INFO - Data split and persistence completed successfully.
2025-11-08 13:12:46,092 - INFO - Data processing completed.
2025-11-08 13:12:46,175 - INFO - Model Training initialised.
2025-11-08 13:12:46,209 - INFO - Data loaded successfully.
2025-11-08 13:12:46,581 - INFO - Model trained and saved successfully at artifacts/models/model.pkl
2025-11-08 13:12:46,722 - INFO - Training model score: 0.91
2025-11-08 13:12:46,741 - INFO - Evaluation Results â€” Accuracy: 0.86 | Precision: 0.85 | Recall: 0.84 | F1-score: 0.84
2025-11-08 13:12:46,758 - INFO - Model training and evaluation completed successfully.
```

This confirms that:

* The **preprocessing** stage produced all expected artefacts.
* The **XGBoost model** was trained and saved successfully.
* The **evaluation metrics** were computed and logged clearly.

## ğŸ§© **Integration Overview**

| File                            | Purpose                                                                                |
| ------------------------------- | -------------------------------------------------------------------------------------- |
| `src/data_processing.py`        | Prepares the raw dataset by cleaning, encoding, and splitting it into train/test sets. |
| `src/model_training.py`         | Trains, evaluates, and persists the XGBoost model using processed artefacts.           |
| `pipeline/training_pipeline.py` | Combines both stages into one reproducible, end-to-end execution pipeline.             |
| `src/logger.py`                 | Handles consistent logging across all pipeline stages.                                 |
| `src/custom_exception.py`       | Provides detailed and contextual error reporting for debugging.                        |

## ğŸ§  **Implementation Highlights**

* **End-to-End Automation:**
  A single command runs the full workflow â€” from raw data to a trained model.

* **Reproducibility:**
  All artefacts (processed data, trained model) are versioned and saved in `artifacts/` for traceability.

* **Error Handling and Logging:**
  Every step includes robust exception handling and timestamped logs for transparency and debugging.

* **Modular Design:**
  Each component (`DataProcessing`, `ModelTraining`) can be developed, tested, or replaced independently.

## âœ… **In summary**

This branch introduces a **fully orchestrated training pipeline**, connecting preprocessing and training into one automated workflow.
It represents a significant milestone in the **MLOps Weather Prediction** project â€” transitioning from modular development to a **complete, operational ML pipeline** ready for:

* CI/CD integration (GitHub Actions, Jenkins, or CircleCI)
* Workflow automation (Airflow or Kubeflow Pipelines)
* Scalable model retraining and deployment in production environments.
