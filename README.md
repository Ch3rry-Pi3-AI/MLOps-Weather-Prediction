# ğŸŒ¦ï¸ **Data Processing â€” MLOps Weather Prediction**

This branch builds upon the **initial setup** by introducing the **`data_processing.py`** module inside `src/`.
It marks the **first executable workflow stage** of the **MLOps Weather Prediction** pipeline â€” responsible for loading raw weather data, cleaning and transforming it, encoding categorical features, and saving train/test splits for model training.

## ğŸ§© **Overview**

The `DataProcessing` class implements a **reproducible preprocessing pipeline** with integrated logging and unified exception handling.
It prepares clean, structured datasets ready for downstream weather forecasting models.

### ğŸ” Core Responsibilities

| Stage | Operation          | Description                                                                               |
| ----: | ------------------ | ----------------------------------------------------------------------------------------- |
|   1ï¸âƒ£ | **Load Data**      | Reads input CSV from `artifacts/raw/weather_data.csv`.                                    |
|   2ï¸âƒ£ | **Preprocess**     | Expands `Date` into `Year`, `Month`, and `Day`, imputes missing values.                   |
|   3ï¸âƒ£ | **Label Encode**   | Converts categorical columns (e.g., wind directions, rain indicators) into numeric codes. |
|   4ï¸âƒ£ | **Split Data**     | Creates 80/20 train/test splits for features and target (`RainTomorrow`).                 |
|   5ï¸âƒ£ | **Save Artefacts** | Writes `X_train.pkl`, `X_test.pkl`, `y_train.pkl`, and `y_test.pkl` to disk.              |

## ğŸ—‚ï¸ **Updated Project Structure**

```text
mlops_weather_prediction/
â”œâ”€â”€ .venv/                          # ğŸ§© Local virtual environment (created by uv)
â”œâ”€â”€ artifacts/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ weather_data.csv        # ğŸŒ¦ï¸ Input weather dataset
â”‚   â””â”€â”€ processed/                  # ğŸ’¾ Output directory for processed data
â”‚       â”œâ”€â”€ X_train.pkl
â”‚       â”œâ”€â”€ X_test.pkl
â”‚       â”œâ”€â”€ y_train.pkl
â”‚       â””â”€â”€ y_test.pkl
â”œâ”€â”€ mlops_weather_prediction.egg-info/ # ğŸ“¦ Package metadata (auto-generated)
â”œâ”€â”€ pipeline/                       # âš™ï¸ Pipeline orchestration (future stage)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ custom_exception.py         # Unified and detailed exception handling
â”‚   â”œâ”€â”€ logger.py                   # Centralised logging configuration
â”‚   â””â”€â”€ data_processing.py          # ğŸŒ¦ï¸ End-to-end weather data preparation
â”œâ”€â”€ static/                         # ğŸŒ Visual assets (optional)
â”œâ”€â”€ templates/                      # ğŸ§© Placeholder for web/API templates
â”œâ”€â”€ .gitignore                      # ğŸš« Git ignore rules
â”œâ”€â”€ .python-version                 # ğŸ Python version pin
â”œâ”€â”€ pyproject.toml                  # âš™ï¸ Project metadata and uv configuration
â”œâ”€â”€ requirements.txt                # ğŸ“¦ Python dependencies
â”œâ”€â”€ setup.py                        # ğŸ”§ Editable install support
â””â”€â”€ uv.lock                         # ğŸ”’ Locked dependency versions
```

## âš™ï¸ **How to Run the Data Processing Module**

After activating the virtual environment and ensuring your dataset is located at `artifacts/raw/weather_data.csv`, run:

```bash
python src/data_processing.py
```

### âœ… **Expected Successful Output**

```console
2025-11-08 11:25:55,985 - INFO - Basic data preprocessing completed.
2025-11-08 11:25:56,012 - INFO - Label mapping for Location: {'Adelaide': 0, 'Albury': 1, 'AliceSprings': 2, ...}
2025-11-08 11:25:56,071 - INFO - Label mapping for WindDir9am: {'E': 0, 'ENE': 1, 'ESE': 2, ...}
2025-11-08 11:25:56,123 - INFO - Label mapping for RainToday: {'No': 0, 'Yes': 1}
2025-11-08 11:25:56,155 - INFO - Label mapping for RainTomorrow: {'No': 0, 'Yes': 1}
2025-11-08 11:25:56,155 - INFO - Label encoding completed.
2025-11-08 11:25:56,167 - INFO - Feature columns: ['Location', 'MinTemp', 'MaxTemp', ... 'Month', 'Day']
2025-11-08 11:25:56,243 - INFO - Data split and persistence completed successfully.
2025-11-08 11:25:56,248 - INFO - Data processing completed.
```

This confirms that:

* The raw dataset was successfully read and parsed.
* Missing values were imputed and date features were expanded.
* Categorical columns were encoded into numeric representations.
* Train/test datasets were created and saved under `artifacts/processed/`.

## ğŸ§  **Implementation Highlights**

* **Integrated Logging** via `src/logger.py`
  Each step logs detailed, timestamped progress messages for full pipeline traceability.

* **Unified Exception Handling** via `src/custom_exception.py`
  Any failure during data loading or transformation raises structured, context-rich errors.

* **Modular, Extensible Design**
  The `DataProcessing` class is importable and designed for integration with later stages â€” including training, evaluation, and Kubeflow orchestration.

## ğŸ§© **Integration Guidelines**

| File                      | Purpose                                                      |
| ------------------------- | ------------------------------------------------------------ |
| `src/data_processing.py`  | Executes the weather data preprocessing workflow end-to-end. |
| `src/custom_exception.py` | Provides consistent, traceable error reporting.              |
| `src/logger.py`           | Ensures structured, timestamped logs for reproducibility.    |

âœ… **In summary:**
This branch transforms the repository from a static scaffold into a **functional preprocessing stage** for the Weather Prediction pipeline â€” producing reproducible artefacts, clean datasets, and structured logs that will power the upcoming **model training and evaluation stages**.
